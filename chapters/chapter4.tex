
\chapter{Numerical Model Fitting}
\label{chapter4}

% 4.1.
\section{Non-Linear Optimisation}

Optimisation methods are, at their heart, minimisation problems (and dually maximisation problems, 
though the two are equivalent). We have some function $f(x)$, called the \textit{objective function},
and some domain $\Omega \subset \R^n$, and we wish to determine
$$\arg\min_{x \in \Omega} f(x)$$
Often the objective function is accompanied by a set of constraints, which more or 
less are used to define the set $\Omega$. If we let $c_i(x) \le 0$ describe one of $k$ constraints that $f$ 
is subject to, then we can describe $\Omega$ as such:
$$\Omega := \lbrace x \in \R^n : c_1(x) \le 0 \; \land c_2(x) \le 0 \land \dots \land c_k(x) \le 0 \rbrace$$

An equivalent formulation of the minimisation problem is in terms of norms. 
\red{Describe minimisation in terms of norms? Ties into least-squares optimisation nicely}

There are a number of difficulties that come packaged with optimisation problems, however. Firstly, 
the method by which you go about minimising your function is dependent on the properties of your function 
- you will have a much easier time minimising a smooth, convex function than you would a discontinuous, 
non-convex function, and different algorithms will net you varying results for each. 

\red{Non-linear functions - introduced via constraints, not necessarily the objective function}

% 4.1.1.
\subsection{Least Squares}

\red{Standard $L_2$ norm explanation and stuff}

\red{Data fitting}

% 4.1.2.
\subsection{Optimisation Algorithms}

Minimising least squares.
\red{Motivate optimisation algorithms}

\subsubsection{Bounded vs non-bounded optimisation}

\subsubsection{Newton's method}

\subsubsection{Gradient descent}

% 4.1.3.
\subsection{MMA Algorithm}

\red{just summarise below more or less}
\red{https://fab.cba.mit.edu/classes/865.18/design/optimization/mma.pdf}

Method of Moving Asymptotes (MMA)

Provide explanation of LD-MMA algorithm. 

% 4.2.
\section{GSH Parameter Fitting}

\red{Talk about why we want to find $a_1, a_2$ and $\alpha$, and how we could go about 
doing that}

% 4.2.1
\subsection{Optimisation Function}

\red{Talk about data we have available}

\red{Construct the objective function}

\red{Bounds for the objective function and justification}

% 4.2.2
\subsection{Parameter Space}

\red{Parameter space a bit cooked}

\red{Show for various zooms}

\red{Talk about asymptotic behaviour with $\alpha$ (justifies MMA usage)}

Graphs showing effect of different parameters

Non-reliance on $\alpha$ (with exception of $\frac{1}{\alpha}$ where $\alpha = 0$ thing)

% 4.2.3
\subsection{Convergence Difficulties}

\red{Could be merged with above?}

Initial difficulties with normalisation. 

% 4.3
\section{Simulated Current Reversals}

\red{Have ability to solve for $a_1, a_2$ and $\alpha$, so next step is 
the ``time perturbation'' - hark back to chapter 3 here}


% 4.3.1
\subsection{Method of Reversal}


\red{Linearly vary current. Could talk about alternatives - i.e. if 
our time perturbation had not been linear but had been trigonometric (to 
fit with a larger scope AC simulation) then our current reversal method 
here could be different}

\red{Feed solved parameters into guess for next. Emphasise problem of not knowing 
the initial ones nonetheless}


% 4.3.2
\subsection{Results and Explanations}

\red{Have still frame shots of the result of that (3x3 tiles?)}

\red{Show the slow version, then the 'zoomed' in version}

\red{Highlight magnetic field topology breaking - suggests RE population generation}

\red{Comment on feasibility of the behaviour - e.g.pressure density profile follows 
magnetic field axis, but then there are things like current densities 
at the edge of the reactor}

